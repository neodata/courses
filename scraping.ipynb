{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "job_list = []\n",
    "for i in range(1,3):\n",
    "    allJobs_url = 'https://www.upwork.com/freelance-jobs/web-scraping/'+str(i)\n",
    "    page = requests.get(allJobs_url)\n",
    "    soup = bs(page.text, \"html5lib\")\n",
    "    divs = soup.find_all(\"div\", class_=\"mb-6x\")\n",
    "    for div in divs:\n",
    "        a = div.find(\"a\")\n",
    "        if (\"/freelance-jobs\" in a[\"href\"]) and (a[\"href\"] not in job_list):\n",
    "            job_list.append(a[\"href\"])\n",
    "\n",
    "job_list = list(set(job_list))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(job_list, columns=[\"Job URL\"])\n",
    "df.to_csv(\"job_list.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=1\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=2\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=3\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=4\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=5\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=6\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=7\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=8\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=9\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=10\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=11\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=12\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=13\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=14\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=15\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=16\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=17\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=18\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=19\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=20\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=21\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=22\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=23\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=24\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=25\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=26\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=27\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=28\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=29\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=30\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=31\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=32\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=33\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=34\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=35\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=36\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=37\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=38\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=39\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=40\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=41\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=42\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=43\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=44\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=45\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=46\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=47\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=48\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=49\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=50\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=51\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=52\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=53\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=54\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=55\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=56\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=57\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=58\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=59\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=60\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=61\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=62\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=63\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=64\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=65\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=66\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=67\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=68\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=69\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=70\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=71\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=72\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=73\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=74\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=75\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=76\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=77\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=78\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=79\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=80\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=81\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=82\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=83\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=84\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=85\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=86\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=87\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=88\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=89\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=90\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=91\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=92\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=93\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=94\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=95\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=96\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=97\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=98\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=99\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=100\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=101\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=102\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=103\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=104\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=105\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=106\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=107\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=108\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=109\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=110\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=111\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=112\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=113\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=114\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=115\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=116\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=117\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=118\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=119\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=120\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=121\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=122\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=123\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=124\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=125\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=126\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=127\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=128\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=129\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=130\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=131\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=132\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=133\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=134\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=135\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=136\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=137\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=138\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=139\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=140\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=141\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=142\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=143\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=144\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=145\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=146\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=147\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=148\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=149\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=150\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=151\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=152\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=153\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=154\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=155\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=156\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=157\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=158\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=159\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=160\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=161\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=162\n",
      "On scrape https://www.barreaudenice.com/annuaire/avocats/?fwp_paged=163\n"
     ]
    }
   ],
   "source": [
    "# Scraping an attorney webpage\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_all_pages():\n",
    "    urls = []\n",
    "    page_number = 1\n",
    "    for i in range(163):\n",
    "        i = \"https://www.barreaudenice.com/annuaire/avocats/?fwp_paged={}\".format(page_number)\n",
    "        page_number += 1\n",
    "        urls.append(i)\n",
    "    return urls\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def parse_attorney(url):\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.content, \"html5lib\")\n",
    "    avocats = soup.find_all(\"div\", class_=\"callout secondary annuaire-single\")\n",
    "    \n",
    "    for avocat in avocats:\n",
    "        try:\n",
    "            nom = avocat.find(\"h3\").text.strip()\n",
    "        except AttributeError as e:\n",
    "            nom = \"\"\n",
    "            \n",
    "        \n",
    "        adresse = avocat.find(\"span\", class_=\"adresse\").text.strip()\n",
    "        try:\n",
    "            adresse_finale = re.sub(r\"\\s+\", \" \", adresse)\n",
    "        except AttributeError as e:\n",
    "            adresse_finale = \"\"\n",
    "        \n",
    "        try:\n",
    "            telephone = avocat.find(\"span\", class_=\"telephone\").text.strip()\n",
    "        except AttributeError as e:\n",
    "            telephone = \"\"\n",
    "        \n",
    "        try:\n",
    "            email = avocat.find(\"span\", class_=\"email\").a.text.strip()\n",
    "        except AttributeError as e:\n",
    "            email = \"\"\n",
    "        \n",
    "        chemin = r\"C:\\Users\\LENOVO\\Documents\\Python\\courses\\annuaire_avocat.txt\"\n",
    "        with open(chemin, \"a\") as f:\n",
    "            f.write(f\"{nom}\\n\")\n",
    "            f.write(f\"{adresse_finale}\\n\")\n",
    "            f.write(f\"{telephone}\\n\")\n",
    "            f.write(f\"{email}\\n\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "def parse_all_attorneys():\n",
    "    pages = get_all_pages()\n",
    "    for page in pages:\n",
    "        parse_attorney(url=page)\n",
    "        print(f\"On scrape {page}\")\n",
    "        \n",
    "parse_all_attorneys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.ibm.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a soup object\n",
    "soup = bs(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ibm.com/granite?lnk=dev\n",
      "https://developer.ibm.com/technologies/artificial-intelligence?lnk=dev\n",
      "https://www.ibm.com/products/watsonx-code-assistant?lnk=dev\n",
      "https://www.ibm.com/watsonx/developer/?lnk=dev\n",
      "https://www.ibm.com/thought-leadership/institute-business-value/report/ceo-generative-ai?lnk=bus\n",
      "https://www.ibm.com/think/reports/ai-in-action?lnk=bus\n",
      "https://www.ibm.com/products/watsonx-orchestrate/ai-agent-for-hr?lnk=bus\n",
      "https://www.ibm.com/products/guardium-data-security-center?lnk=bus\n",
      "https://www.ibm.com/artificial-intelligence?lnk=ProdC\n",
      "https://www.ibm.com/hybrid-cloud?lnk=ProdC\n",
      "https://www.ibm.com/consulting?lnk=ProdC\n"
     ]
    }
   ],
   "source": [
    "# Scrap all links\n",
    "\n",
    "links = soup.find_all(\"a\", href=True)\n",
    "for link in links:\n",
    "    print(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap all images\n",
    "images = soup.find_all(\"img\", src=True)\n",
    "for image in images:\n",
    "    print(image.get(\"src\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name------------>None\n",
      "lightsalmon------------>rgb(255,160,122)\n",
      "salmon------------>rgb(250,128,114)\n",
      "darksalmon------------>rgb(233,150,122)\n",
      "lightcoral------------>rgb(240,128,128)\n",
      "coral------------>rgb(255,127,80)\n",
      "tomato------------>rgb(255,99,71)\n",
      "orangered------------>rgb(255,69,0)\n",
      "gold------------>rgb(255,215,0)\n",
      "orange------------>rgb(255,165,0)\n",
      "darkorange------------>rgb(255,140,0)\n",
      "lightyellow------------>rgb(255,255,224)\n",
      "lemonchiffon------------>rgb(255,250,205)\n",
      "papayawhip------------>rgb(255,239,213)\n",
      "moccasin------------>rgb(255,228,181)\n",
      "peachpuff------------>rgb(255,218,185)\n",
      "palegoldenrod------------>rgb(238,232,170)\n",
      "khaki------------>rgb(240,230,140)\n",
      "darkkhaki------------>rgb(189,183,107)\n",
      "yellow------------>rgb(255,255,0)\n",
      "lawngreen------------>rgb(124,252,0)\n",
      "chartreuse------------>rgb(127,255,0)\n",
      "limegreen------------>rgb(50,205,50)\n",
      "lime------------>rgb(0.255.0)\n",
      "forestgreen------------>rgb(34,139,34)\n",
      "green------------>rgb(0,128,0)\n",
      "powderblue------------>rgb(176,224,230)\n",
      "lightblue------------>rgb(173,216,230)\n",
      "lightskyblue------------>rgb(135,206,250)\n",
      "skyblue------------>rgb(135,206,235)\n",
      "deepskyblue------------>rgb(0,191,255)\n",
      "lightsteelblue------------>rgb(176,196,222)\n",
      "dodgerblue------------>rgb(30,144,255)\n"
     ]
    }
   ],
   "source": [
    "# Scrap data from html tables\n",
    "\n",
    "# import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = bs(page.text, \"html5lib\")\n",
    "\n",
    "tables = soup.find(\"table\")\n",
    "\n",
    "rows = tables.find_all(\"tr\")\n",
    "for row in rows:\n",
    "    columns = row.find_all(\"td\")\n",
    "    color_name = columns[2].string\n",
    "    code_color = columns[4].string\n",
    "    print(\"{}------------>{}\".format(color_name, code_color))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area</th>\n",
       "      <th>Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5,921,231</td>\n",
       "      <td>719</td>\n",
       "      <td>8,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>165,650,475</td>\n",
       "      <td>148,460</td>\n",
       "      <td>1,116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine[note 3][100]</td>\n",
       "      <td>5,223,000</td>\n",
       "      <td>6,025</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan[note 4]</td>\n",
       "      <td>23,580,712</td>\n",
       "      <td>35,980</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51,844,834</td>\n",
       "      <td>99,720</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>5,296,814</td>\n",
       "      <td>10,400</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>13,173,730</td>\n",
       "      <td>26,338</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>12,696,478</td>\n",
       "      <td>27,830</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9,402,617</td>\n",
       "      <td>21,937</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1,389,637,446</td>\n",
       "      <td>3,287,263</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                 Country     Population       Area Density\n",
       "0    1               Singapore      5,921,231        719   8,235\n",
       "1    2              Bangladesh    165,650,475    148,460   1,116\n",
       "2    3  Palestine[note 3][100]      5,223,000      6,025     867\n",
       "3    4          Taiwan[note 4]     23,580,712     35,980     655\n",
       "4    5             South Korea     51,844,834     99,720     520\n",
       "5    6                 Lebanon      5,296,814     10,400     509\n",
       "6    7                  Rwanda     13,173,730     26,338     500\n",
       "7    8                 Burundi     12,696,478     27,830     456\n",
       "8    9                  Israel      9,402,617     21,937     429\n",
       "9   10                   India  1,389,637,446  3,287,263     423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape data from HTML tables into a DataFrame using BeautifulSoup and Pandas\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "# The URL of the wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\"\n",
    "\n",
    "# Get the page content\n",
    "page = requests.get(url).text\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "soup = bs(page, \"html5lib\")\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = soup.find_all(\"table\")\n",
    "\n",
    "# Count how many tables are on the page\n",
    "len(tables)\n",
    "\n",
    "# Check if we can find the correct table with a clearer match\n",
    "table_index = None\n",
    "\n",
    "for index,table in enumerate(tables):\n",
    "    # Looking for the table heading that matches \"10 most densely populated countries\"\n",
    "    if(\"10 most densely populated countries\" in str(table)):\n",
    "        table_index = index\n",
    "        break\n",
    "\n",
    "\n",
    "# Create an empty list\n",
    "population_data = []\n",
    "\n",
    "# Get the tbody from the identified table listed: 10 most densely populated countries\n",
    "table_8 = tables[table_index].tbody\n",
    "\n",
    "# All the rows of table_8\n",
    "rows_tab = table_8.find_all(\"tr\")\n",
    "\n",
    "# Loop through each row and extract the data\n",
    "for row in rows_tab:\n",
    "    col = row.find_all(\"td\")\n",
    "    if len(col) >= 5:           #Ensure that there are at least 5 columns (Rank, Country, Population, Area, Density)\n",
    "        # Extract the relevant data and clean it\n",
    "        rank = col[0].text.strip()\n",
    "        country = col[1].text.strip()\n",
    "        population = col[2].text.strip()\n",
    "        area = col[3].text.strip()\n",
    "        density = col[4].text.strip()\n",
    "        \n",
    "        # Append the data as a tuple to the list\n",
    "        population_data.append([rank, country, population, area, density])\n",
    "\n",
    "# Convert the list into a dataframe\n",
    "population_df = pd.DataFrame(population_data, columns=[\"Rank\", \"Country\", \"Population\", \"Area\", \"Density\"])\n",
    "\n",
    "# Display the result\n",
    "population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16228\\3744016499.py:19: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  pd.read_html(str(tables[8]), flavor='bs4')\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16228\\3744016499.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  population_data_read_html = pd.read_html(str(tables[8]), flavor='bs4')[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (km2)</th>\n",
       "      <th>Density (pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5921231</td>\n",
       "      <td>719</td>\n",
       "      <td>8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>165650475</td>\n",
       "      <td>148460</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine[note 3][100]</td>\n",
       "      <td>5223000</td>\n",
       "      <td>6025</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan[note 4]</td>\n",
       "      <td>23580712</td>\n",
       "      <td>35980</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51844834</td>\n",
       "      <td>99720</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>5296814</td>\n",
       "      <td>10400</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>13173730</td>\n",
       "      <td>26338</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>12696478</td>\n",
       "      <td>27830</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9402617</td>\n",
       "      <td>21937</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1389637446</td>\n",
       "      <td>3287263</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                 Country  Population  Area (km2)  Density (pop/km2)\n",
       "0     1               Singapore     5921231         719               8235\n",
       "1     2              Bangladesh   165650475      148460               1116\n",
       "2     3  Palestine[note 3][100]     5223000        6025                867\n",
       "3     4          Taiwan[note 4]    23580712       35980                655\n",
       "4     5             South Korea    51844834       99720                520\n",
       "5     6                 Lebanon     5296814       10400                509\n",
       "6     7                  Rwanda    13173730       26338                500\n",
       "7     8                 Burundi    12696478       27830                456\n",
       "8     9                  Israel     9402617       21937                429\n",
       "9    10                   India  1389637446     3287263                423"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape data from HTML tables into a DataFrame using BeautifulSoup and read_html\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "# The URL of the wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\"\n",
    "\n",
    "# Get the page content\n",
    "page = requests.get(url).text\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "soup = bs(page, \"html5lib\")\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = soup.find_all(\"table\")\n",
    "\n",
    "# Scrape data from HTML tables into a DataFrame using BeautifulSoup and read_html\n",
    "pd.read_html(str(tables[8]), flavor='bs4')\n",
    "population_data_read_html = pd.read_html(str(tables[8]), flavor='bs4')[0]\n",
    "\n",
    "population_data_read_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (km2)</th>\n",
       "      <th>Density (pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5921231</td>\n",
       "      <td>719</td>\n",
       "      <td>8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>165650475</td>\n",
       "      <td>148460</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine[note 3][100]</td>\n",
       "      <td>5223000</td>\n",
       "      <td>6025</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan[note 4]</td>\n",
       "      <td>23580712</td>\n",
       "      <td>35980</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51844834</td>\n",
       "      <td>99720</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>5296814</td>\n",
       "      <td>10400</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>13173730</td>\n",
       "      <td>26338</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>12696478</td>\n",
       "      <td>27830</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9402617</td>\n",
       "      <td>21937</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1389637446</td>\n",
       "      <td>3287263</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                 Country  Population  Area (km2)  Density (pop/km2)\n",
       "0     1               Singapore     5921231         719               8235\n",
       "1     2              Bangladesh   165650475      148460               1116\n",
       "2     3  Palestine[note 3][100]     5223000        6025                867\n",
       "3     4          Taiwan[note 4]    23580712       35980                655\n",
       "4     5             South Korea    51844834       99720                520\n",
       "5     6                 Lebanon     5296814       10400                509\n",
       "6     7                  Rwanda    13173730       26338                500\n",
       "7     8                 Burundi    12696478       27830                456\n",
       "8     9                  Israel     9402617       21937                429\n",
       "9    10                   India  1389637446     3287263                423"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "# The URL of the wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\"\n",
    "\n",
    "# Scrape data from HTML tables into a DataFrame using read_html\n",
    "dataframe_list = pd.read_html(url, flavor='bs4')\n",
    "dataframe_list[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
